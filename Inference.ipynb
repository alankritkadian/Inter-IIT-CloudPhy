{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW_oEkcd-ToB"
      },
      "source": [
        "# Importing Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I5GDas6CWIZ",
        "outputId": "fd5078da-3901-484a-d330-c691f9880b6f"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U14SMKxdCViQ"
      },
      "outputs": [],
      "source": [
        "from PIL import Image \n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4lERdd1EV-U",
        "outputId": "3501f21f-f66c-4e90-af62-b890f42dc7ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nW5wMnBCT_-"
      },
      "source": [
        "# Segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ntyWitivSK",
        "outputId": "3437e874-5f52-42b3-9e22-afb173fdc4be"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmtbvkjvnQzJ"
      },
      "outputs": [],
      "source": [
        "def segment(image):\n",
        "  import base64\n",
        "  from roboflow import Roboflow\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  import numpy as np\n",
        "\n",
        "  image_read = cv2.imread(image)\n",
        "  rf = Roboflow(api_key=\"EELutg6OW9WGerWim8P2\")\n",
        "  project = rf.workspace(\"monitor-detection\").project(\"monitor-screen-detection-lcrfl\")\n",
        "  model = project.version(1).model\n",
        "  image_read = cv2.resize(image_read, (1280,720),interpolation = cv2.INTER_CUBIC)\n",
        "  # infer on a local image\n",
        "  # model.predict(image).save(\"prediction.jpg\") \n",
        "  result = model.predict(image).json()\n",
        "  im_b64 = result['predictions'][0]['segmentation_mask']\n",
        "  im_bytes = base64.b64decode(im_b64)\n",
        "  im_arr = np.frombuffer(im_bytes, dtype=np.uint8)  # im_arr is one-dim Numpy array\n",
        "  img = cv2.imdecode(im_arr, flags=cv2.IMREAD_UNCHANGED)\n",
        "  img = cv2.resize(img, (1280,720),interpolation = cv2.INTER_CUBIC)\n",
        "  # print(img.shape)\n",
        "  pts = []\n",
        "  found = 0\n",
        "  for i in range(0,720):\n",
        "    for j in range(0,1280):\n",
        "      if img[i][j]==0:\n",
        "        image_read[i][j] = 0\n",
        "  # plt.subplot(141);plt.imshow(image_read,cmap=\"gray\")\n",
        "  # plt.subplot(142);plt.imshow(image_read)\n",
        "\n",
        "\n",
        "  # plt.show()\n",
        "  return image_read"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFz6hGa9-rcR"
      },
      "source": [
        "# Cropping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SyGcP0T-xqC"
      },
      "outputs": [],
      "source": [
        "def cropping(image,pts):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  import numpy as np\n",
        "  width = 1280\n",
        "  height = 720\n",
        "  pts = np.float32(pts)\n",
        "  converted_points = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
        "  img = cv2.imread(image)\n",
        "  matrix = cv2.getPerspectiveTransform(pts,converted_points)\n",
        "  img_output = cv2.warpPerspective(img, matrix, (width,height))\n",
        "  plt.imshow(img_output)\n",
        "  plt.show()\n",
        "  return "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDBIclee-XKq"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj555Y3Y-Xgw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras.utils as image\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "def classify(img):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = Image.fromarray(img)\n",
        "  img = img.resize((256,256))\n",
        "  img = np.array(img)\n",
        "  test_img = np.expand_dims(img,axis=0)\n",
        "  classifier = tf.keras.models.load_model('/content/drive/MyDrive/CloudPhy/Image_Classification.h5')\n",
        "  cls=np.argmax(classifier.predict(test_img),axis=1)\n",
        "  ans = cls[0]\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RbkITNz-dN9"
      },
      "source": [
        "# Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHAIgypJ4IOq"
      },
      "outputs": [],
      "source": [
        "  import os \n",
        "  import glob as glob\n",
        "  import matplotlib.pyplot as plt\n",
        "  import cv2\n",
        "  import requests\n",
        "  import random\n",
        "  import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4rbN95d2-Ji"
      },
      "outputs": [],
      "source": [
        "def inference_obj(data_path):\n",
        "    # Directory to store inference results.\n",
        "    infer_dir_count = len(glob.glob('runs/detect/*'))\n",
        "    print(f\"Current number of inference detection directories: {infer_dir_count}\")\n",
        "    INFER_DIR = f\"inference_{infer_dir_count+1}\"\n",
        "    print(INFER_DIR)\n",
        "    # Inference on images.\n",
        "    !python detect.py --weights runs/train/results_0/weights/best.pt \\\n",
        "    --source {data_path} --name {INFER_DIR} --save-crop\n",
        "    return INFER_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epZCE0eiq5ph"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def getPropsFiles(path):\n",
        "    file1 = []\n",
        "    file2 = []\n",
        "    props = f'{path}/'\n",
        "    for f in os.listdir(props):\n",
        "        f_path = os.path.join(props, f)\n",
        "        if os.path.isfile(f_path):\n",
        "            print(f)\n",
        "        if \"_W\" in f_path:\n",
        "            file1.append(f_path)\n",
        "        else:\n",
        "            file2.append(f_path)\n",
        "    return file1, file2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y1trE7Y-aj1"
      },
      "source": [
        "# OCR Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZsZn12q-gIb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def ocr_task(arr):\n",
        "  crops = []\n",
        "  result = {}\n",
        "  for x in arr:\n",
        "    for file in os.listdir(f'{x}/'):\n",
        "      img = cv2.imread(f'{x}/{file}')\n",
        "      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "      kernel = np.array([[-1, -1, -1], \n",
        "                         [-1, 9, -1], \n",
        "                         [-1, -1, -1]]\n",
        "                        )\n",
        "      sharpened = cv2.filter2D(blurred, -1, kernel)\n",
        "      im8 = 0\n",
        "      im7 = 0\n",
        "      try:\n",
        "        im8 =int(pytesseract.image_to_string(sharpened, lang='eng', config='--psm 8 -c tessedit_char_whitelist=0123456789 '))\n",
        "      except :\n",
        "        im8 =0\n",
        "      try:\n",
        "        im7 = int(pytesseract.image_to_string(sharpened,lang='eng', config='--psm 7 -c tessedit_char_whitelist=0123456789 '))\n",
        "      except:\n",
        "        im7 = 0\n",
        "      res = max(im7, im8)\n",
        "      if \"HR\" in x:\n",
        "        result[\"HR\"] = res\n",
        "      if \"SBP\" in x:\n",
        "        result[\"SBP\"] = res\n",
        "      if \"DBP\" in x:\n",
        "        result[\"DBP\"] = res\n",
        "      if \"MAP\" in x:\n",
        "        result[\"MAP\"] = res\n",
        "      if \"SPO\" in x:\n",
        "        result[\"SPO\"] = res\n",
        "      if \"RR\" in x:\n",
        "        result[\"RR\"] = res\n",
        "  return result # dice containg value of heart rate, spo2 etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_gvOkkG-gdI"
      },
      "source": [
        "# Brownie Point Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv6rEqf9-ion",
        "outputId": "11ee8498-dc58-4962-96fa-a3362f30db6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: potracer in /usr/local/lib/python3.8/dist-packages (0.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from potracer) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install potracer\n",
        "#image is a rgb image of the graph\n",
        "def brownie(image):\n",
        "  from potrace import Bitmap\n",
        "  img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "  ret,thresh1 = cv2.threshold(img,200,255,cv2.THRESH_BINARY)\n",
        "  t_lower = 50 \n",
        "  t_upper = 150   \n",
        "  edge = cv2.Canny(thresh1, t_lower, t_upper)\n",
        "  bitmap = Bitmap(edge)\n",
        "  path = bitmap.trace()  \n",
        "  for curve in path:\n",
        "    print (\"Start Point of Curve:\", curve.start_point)\n",
        "    for segment in curve:\n",
        "      print(\"Segment Point:\",segment.end_point)\n",
        "      if segment.is_corner:\n",
        "          print(\"Corner Point:\",segment.c)\n",
        "      else:\n",
        "          print(\"BezierSegment Start Point:\",segment.c1)\n",
        "          print(\"BezierSegment End Point:\",segment.c2)\n",
        "\n",
        "  return path  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C-2FT_F-i-t"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNxF489qAQeR"
      },
      "outputs": [],
      "source": [
        "def inference(image_path:str): # dict\n",
        "  '''\n",
        "  Function responsible for inference.\n",
        "  Args: \n",
        "    image_path: str, path to image file. eg. \"input/aveksha_micu_mon--209_2023_1_17_12_0_34.jpeg\"\n",
        "  Returns:\n",
        "    result: dict, final output dictionary. eg. {\"HR\":\"80\", \"SPO2\":\"98\", \"RR\":\"15\", \"SBP\":\"126\", \"DBP\":\"86\"}\n",
        "  '''\n",
        "  image_read_user = segment(image_path)\n",
        "  cv2.imwrite('/content/drive/MyDrive/CloudPhy/infer/cropped.jpg',image_read_user)\n",
        "  class_screen = classify(image_read_user)\n",
        "  %ls\n",
        "  %cd /content/drive/MyDrive/CloudPhy/yolov5_{class_screen}/\n",
        "  !pwd\n",
        "  !pip install -r requirements.txt\n",
        "  IMAGE_INFER_DIR = inference_obj('/content/drive/MyDrive/CloudPhy/infer')\n",
        "  PATH_CROPS = f'/content/drive/MyDrive/CloudPhy/yolov5_{class_screen}/runs/detect/{IMAGE_INFER_DIR}/crops'\n",
        "  arr1, arr2 = getPropsFiles(PATH_CROPS)\n",
        "  print(arr1)\n",
        "  print(arr2)\n",
        "  result = ocr_task(arr2)\n",
        "  for x in arr1:\n",
        "    for file in os.listdir(f'{x}/'):\n",
        "      image_super = cv2.imread(f'{x}/{file}')\n",
        "      brownie(image_super)\n",
        "  ## put your code here\n",
        "  \n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH-7KF0LtnT_",
        "outputId": "9dd11df0-4ce6-4b87-ebf8-9219be32f3fc"
      },
      "outputs": [],
      "source": [
        "result = inference('/content/drive/MyDrive/tridevdeoghar_icu_mon--4_2023_1_2_19_20_52.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWgE0DI1tw52",
        "outputId": "1245110a-d0dd-42f7-c3ff-263b5f23d014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'DBP': 60}\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
